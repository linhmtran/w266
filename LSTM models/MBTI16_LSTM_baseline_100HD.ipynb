{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline LSTM MBTI Classification Model\n",
    "\n",
    "First, load libraries and useful functions from class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import json, os, re, shutil, sys, time\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# Utils and Helper libraries\n",
    "# import nltk\n",
    "from w266_common import utils, vocabulary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import MBTI_data_setup as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus & Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv('./mbti_1.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422845, 3)\n",
      "MBIT posts ['https://www.youtube.com/watch?v=bxvkaah2d7m'\n",
      " 'isfjs and infps can balance each other really well, i think, if they learn to communicate - sjs choosing words (and tone of voice!) carefully, and nps learning to take things less personally. your sj...'\n",
      " \"i'd seek recognition. not fame.\"\n",
      " \"to be honest, maybe you are giving out vibes that you are not self-assured. because if you think about it, a bully is going to go for someone they don't think will fight back, someone who is weak (i...\"\n",
      " \"probably. any thinking, really. personally, i prefer the ax-b-c-dy function stack compared to grant's. it allows for the parts where grant gets it right while still being consistent with jung, i.e.,...\"]\n",
      "\n",
      "MBTI Labels:  ['INTP' 'INFP' 'INTP' 'ENFP' 'INTJ']\n",
      "Vocab Size:  333007\n",
      "[ 2 12]\n",
      "[12  0]\n",
      "[[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "reload(ds)\n",
    "post, mbti_type, user = ds.splitPosts(df)\n",
    "\n",
    "# Split data: 80% train, 20% test\n",
    "post_train, post_test, label_train, label_test = train_test_split(post, mbti_type, test_size=0.2, random_state=88)\n",
    "\n",
    "print(\"MBIT posts\", post_train[:5])\n",
    "print('')\n",
    "print(\"MBTI Labels: \",label_train[:5])\n",
    "\n",
    "# Build a vocabulary (V size is defaulted to full text) for train corpus\n",
    "vocab_mbti = vocabulary.Vocabulary((utils.canonicalize_word(w) for w in post_train))\n",
    "print(\"Vocab Size: \",vocab_mbti.size)\n",
    "\n",
    "# tokenize and canonicalize train and test sets\n",
    "x_train = []\n",
    "for post in post_train:\n",
    "    x_train.append(vocab_mbti.words_to_ids(post.split()))\n",
    "\n",
    "x_test = []\n",
    "for post in post_test:\n",
    "    x_test.append(vocab_mbti.words_to_ids(post.split()))\n",
    "    \n",
    "reload(ds)\n",
    "y_train, y_test = ds.one_hot_label(mbti_type, label_train, label_test)\n",
    "y_train_id, y_test_id, label_map = ds.label_to_id(mbti_type, label_train, label_test)\n",
    "\n",
    "print(y_train_id[:2])\n",
    "print(y_test_id[:2])\n",
    "print(y_train[:2])\n",
    "print(y_test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulid the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "V = vocab_mbti.size\n",
    "classes = 16 #len(set(labels))\n",
    "batch_size = 25\n",
    "text_length = 70 # max sentence is 66\n",
    "embed_dim = 50 #256\n",
    "hidden_dims = 100 #\n",
    "num_layers = 1\n",
    "\n",
    "# Training Parameters\n",
    "dropout_keep_prob = .5\n",
    "softmax_ns = 4\n",
    "learning_rate = .001\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# useful functions for building LSTM\n",
    "def MakeFancyRNNCell(hidden_dims, keep_prob, layers=1, isTrain=True):\n",
    "    \"\"\"Make a fancy RNN cell.\n",
    "\n",
    "    Use tf.nn.rnn_cell functions to construct an LSTM cell.\n",
    "    Initialize forget_bias=0.0 for better training.\n",
    "\n",
    "    Args:\n",
    "      H: hidden state sizes, provided in array\n",
    "      keep_prob: dropout keep prob (same for input and output)\n",
    "\n",
    "    Returns:\n",
    "      (tf.nn.rnn_cell.RNNCell) multi-layer LSTM cell with dropout\n",
    "    \"\"\"\n",
    "    if isTrain == False:\n",
    "        keep_prob = 1.0\n",
    "\n",
    "    cells = []\n",
    "    for _ in range(layers):\n",
    "#         cell = tf.nn.rnn_cell.BasicLSTMCell(H, forget_bias=0.0) #deprecated?\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_dims, forget_bias=0.0,state_is_tuple=True)\n",
    "        cell = tf.nn.rnn_cell.DropoutWrapper(cell, \n",
    "                                             input_keep_prob=keep_prob, \n",
    "                                             output_keep_prob=keep_prob)\n",
    "        cells.append(cell)\n",
    "    return tf.nn.rnn_cell.MultiRNNCell(cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Input:  (?, ?, 50)\n",
      "LSTM Cell output shape:  (?, ?, 50)\n",
      "fully connected output shape:  (?, 50)\n",
      "W_out:  (50, 16)\n",
      "Logits:  (?, 16)\n",
      "Pred Prob Shape:  (?, 16)\n",
      "Pred Max Shape:  (?,)\n",
      "Sampling Shape:  (?, 1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(88)\n",
    "    \n",
    "# Create input placeholder\n",
    "with tf.name_scope(\"Inputs\"):\n",
    "    x_text_ = tf.placeholder(tf.int32, [None, None], name=\"x_text\") #batch x text_length\n",
    "    y_type_ = tf.placeholder(tf.int32, [None,classes], name=\"y_type\") #batch x classes\n",
    "\n",
    "    \n",
    "# Model params\n",
    "with tf.name_scope(\"Dynamic_Params\"):\n",
    "    # Get dynamic shape info from inputs\n",
    "    batch_size_ = tf.shape(x_text_)[0]\n",
    "    text_length_ = text_length\n",
    "    ns_ = tf.tile([text_length], [batch_size_, ], name=\"ns\")\n",
    "    isTrain_ = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "# Construct embedding layer\n",
    "with tf.name_scope(\"Embedding_Layer\"):\n",
    "#     W_in_ = tf.get_variable(tf.random_uniform(-1.0, 1.0),shape=[V, embed_dim], name=\"W_in\")\n",
    "    W_in_ = tf.Variable(tf.random_uniform([V, embed_dim], -1.0, 1.0), name=\"W_in\")\n",
    "    x_ = tf.nn.embedding_lookup(W_in_, x_text_,name='x')\n",
    "    print(\"Embedded Input: \", x_.shape)\n",
    "\n",
    "# Construct RNN/LSTM cell and recurrent layer.\n",
    "with tf.name_scope(\"Recurrent_Layer\"):\n",
    "    cell_lstm_ = MakeFancyRNNCell(hidden_dims, dropout_keep_prob, num_layers,isTrain_)\n",
    "    initial_h_ = cell_lstm_.zero_state(batch_size_, dtype=tf.float32)\n",
    "    output_, final_h_= tf.nn.dynamic_rnn(cell=cell_lstm_, inputs=x_, \n",
    "                                         sequence_length= ns_, initial_state = initial_h_, dtype=tf.float32)\n",
    "    print(\"LSTM Cell output shape: \",output_.shape)\n",
    "\n",
    "with tf.name_scope(\"Output_Layer\"):\n",
    "    h_ = tf.reduce_sum(output_, 1)\n",
    "    fully_connected_ = tf.layers.dense(h_, hidden_dims, activation=tf.tanh)\n",
    "    fc_do_ = tf.layers.dropout(inputs=fully_connected_, rate=(1-dropout_keep_prob), training=isTrain_)\n",
    "    if isTrain_==True:\n",
    "        fully_connected_ = fc_do_\n",
    "    print(\"fully connected output shape: \",fully_connected_.shape)\n",
    "    W_out_ = tf.Variable(tf.random_uniform([int(fully_connected_.shape[1]),classes],-1.0, 1.0), name=\"W_out\")\n",
    "    print(\"W_out: \",W_out_.shape)\n",
    "    b_out_ = tf.Variable(tf.zeros([classes,], dtype=tf.float32), name=\"b_out\")\n",
    "    logits_ = tf.add(tf.matmul(fully_connected_,W_out_), b_out_, name=\"logits\")\n",
    "    print(\"Logits: \",logits_.shape)\n",
    "    \n",
    "#     output_ = tf.reshape(output_, [batch_size_,text_length*hidden_dims])\n",
    "#     print(\"flattened output shape: \",output_.shape)\n",
    "#     W_out_ = tf.Variable(tf.random_uniform([hidden_dims*text_length,classes],-1.0, 1.0), name=\"W_out\")\n",
    "#     print(\"W_out: \",W_out_.shape)\n",
    "#     b_out_ = tf.Variable(tf.zeros([classes,], dtype=tf.float32), name=\"b_out\")\n",
    "#     logits_ = tf.add(tf.matmul(output_,W_out_), b_out_, name=\"logits\")\n",
    "#     print(\"Logits: \",logits_.shape)\n",
    "\n",
    "        \n",
    "\n",
    "with tf.name_scope(\"Cost_Function\"):\n",
    "    # Full softmax loss for training / scoring\n",
    "    per_example_loss_ = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_type_, \n",
    "                                                                   logits=logits_,\n",
    "                                                                   name=\"per_example_loss\")\n",
    "    loss_ = tf.reduce_mean(per_example_loss_, name=\"loss\")\n",
    "    \n",
    "    # Sampled softmax for training\n",
    "    train_inputs_ = tf.reshape(output_, [batch_size_*text_length_,-1])\n",
    "\n",
    "    per_example_sampled_softmax_loss_ = tf.nn.sampled_softmax_loss(weights=tf.transpose(W_out_),\n",
    "                                                                   biases=b_out_,\n",
    "                                                                   labels=tf.reshape(y_type_, [-1, 1]),\n",
    "                                                                   inputs=train_inputs_,\n",
    "                                                                   num_sampled=softmax_ns, \n",
    "                                                                   num_classes=classes,\n",
    "                                                                   name=\"per_example_sampled_softmax_loss\")\n",
    "\n",
    "    sampled_softmax_loss_ = tf.reduce_mean(per_example_sampled_softmax_loss_, name=\"sampled_softmax_loss\")\n",
    "    \n",
    "with tf.name_scope(\"Prediction\"):\n",
    "    pred_proba_ = tf.nn.softmax(logits_, name=\"pred_proba\")\n",
    "    pred_max_ = tf.argmax(logits_, 1, name=\"pred_max\")\n",
    "    pred_random_ = tf.reshape(tf.multinomial(tf.reshape(logits_ , [-1, classes]), \n",
    "                                                          1, \n",
    "                                                          output_dtype=tf.int32, \n",
    "                                                          name=\"pred_random\"),\n",
    "                                           [batch_size_,1])\n",
    "    print(\"Pred Prob Shape: \",pred_proba_.shape)\n",
    "    print(\"Pred Max Shape: \",pred_max_.shape)\n",
    "    print(\"Sampling Shape: \",pred_random_.shape)\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"Train\"):\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    optimizer_ = tf.train.AdamOptimizer(learning_rate_)\n",
    "    gradients, variables = zip(*optimizer_.compute_gradients(loss_))\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "    train_step_ = optimizer_.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "# Initializer step\n",
    "init_ = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w\n",
    "summary_writer = tf.summary.FileWriter(\"tf_graph\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create batched arrays of size batch_size based on input x and input y\n",
    "def pad_np_array(example_ids, max_len=text_length, pad_id=0):\n",
    "    arr = np.full([len(example_ids), max_len], pad_id, dtype=np.int32)\n",
    "    ns = np.zeros([len(example_ids)], dtype=np.int32)\n",
    "    for i, ids in enumerate(example_ids):\n",
    "        cpy_len = min(len(ids), max_len)\n",
    "        arr[i,:cpy_len] = ids[:cpy_len]\n",
    "        ns[i] = cpy_len\n",
    "    return arr, ns\n",
    "\n",
    "def batch_generator(x, y, batch_size):\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        # padd the batch\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        x_padded, _ = pad_np_array(x_batch, max_len=text_length, pad_id=0)\n",
    "        yield (x_padded, y[i:i+batch_size]) # returns tuple of batched x, batched y\n",
    "\n",
    "def train_batch(session, xbatch, ybatch, learning_rate):\n",
    "    feed_dict = {x_text_:xbatch, #np array of texts\n",
    "                 y_type_:ybatch, #np array of types\n",
    "                 learning_rate_:learning_rate}\n",
    "#     c, _ = session.run([sampled_softmax_loss_, train_step_],\n",
    "    c, _ = session.run([loss_, train_step_],\n",
    "                       feed_dict=feed_dict)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[epoch 1] seen 0 batches\n",
      "[epoch 1] Completed 199 batches in 0:00:36\n",
      "[epoch 1] Average cost: 3.547\n",
      "\n",
      "[epoch 2] seen 0 batches\n",
      "[epoch 2] Completed 199 batches in 0:00:35\n",
      "[epoch 2] Average cost: 2.573\n",
      "\n",
      "[epoch 3] seen 0 batches\n",
      "[epoch 3] Completed 199 batches in 0:00:35\n",
      "[epoch 3] Average cost: 2.367\n",
      "\n",
      "[epoch 4] seen 0 batches\n",
      "[epoch 4] Completed 199 batches in 0:00:30\n",
      "[epoch 4] Average cost: 2.305\n",
      "\n",
      "[epoch 5] seen 0 batches\n",
      "[epoch 5] Completed 199 batches in 0:00:30\n",
      "[epoch 5] Average cost: 2.276\n"
     ]
    }
   ],
   "source": [
    "print_interval = 1000\n",
    "\n",
    "np.random.seed(88)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(init_)\n",
    "\n",
    "t0 = time.time()\n",
    "# open('results/MBTI16_LSTM_baseline_100HD_pilot1000.txt', 'w').close()\n",
    "# with open('results/MBTI16_LSTM_baseline_100HD_pilot1000.txt', 'a') as f:\n",
    "#     f.write('TRAINING PILOT 1000 \\n')\n",
    "#     for epoch in range(1,num_epochs+1):\n",
    "#         t0_epoch = time.time()\n",
    "#         epoch_cost = 0.0\n",
    "#         total_batches = 0\n",
    "#         print (\"\")\n",
    "#         for i, (x,y) in enumerate(batch_generator(x_train[:1000], y_train[:1000], batch_size)): # for pilot\n",
    "#             if (i % print_interval == 0):\n",
    "#                 print(\"[epoch %d] seen %d batches\" % (epoch, i))\n",
    "\n",
    "#             epoch_cost += train_batch(session, x, y, learning_rate)\n",
    "#             total_batches = i + 1\n",
    "\n",
    "#         avg_cost = epoch_cost / total_batches\n",
    "#         f.write(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)) +'\\n')\n",
    "#         f.write(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,)+'\\n')\n",
    "#         print(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)))\n",
    "#         print(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,))\n",
    "        \n",
    "# open('results/MBTI16_LSTM_baseline_100HD_pilot5000.txt', 'w').close()\n",
    "# with open('results/MBTI16_LSTM_baseline_100HD_pilot5000.txt', 'a') as f:\n",
    "#     f.write('TRAINING PILOT 5000 \\n')\n",
    "#     for epoch in range(1,num_epochs+1):\n",
    "#         t0_epoch = time.time()\n",
    "#         epoch_cost = 0.0\n",
    "#         total_batches = 0\n",
    "#         print (\"\")\n",
    "#         for i, (x,y) in enumerate(batch_generator(x_train[:5000], y_train[:5000], batch_size)): # for pilot\n",
    "#             if (i % print_interval == 0):\n",
    "#                 print(\"[epoch %d] seen %d batches\" % (epoch, i))\n",
    "\n",
    "#             epoch_cost += train_batch(session, x, y, learning_rate)\n",
    "#             total_batches = i + 1\n",
    "\n",
    "#         avg_cost = epoch_cost / total_batches\n",
    "#         f.write(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)) +'\\n')\n",
    "#         f.write(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,)+'\\n')\n",
    "#         print(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)))\n",
    "#         print(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,))\n",
    "\n",
    "open('results/MBTI16_LSTM_baseline_100HD.txt', 'w').close()\n",
    "with open('results/MBTI16_LSTM_baseline_100HD.txt', 'a') as f:\n",
    "    f.write('TRAINING Full \\n')\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        epoch_cost = 0.0\n",
    "        total_batches = 0\n",
    "        print (\"\")\n",
    "        for i, (x,y) in enumerate(batch_generator(x_train, y_train, batch_size)):\n",
    "            if (i % print_interval == 0):\n",
    "                print(\"[epoch %d] seen %d batches\" % (epoch, i))\n",
    "\n",
    "            epoch_cost += train_batch(session, x, y, learning_rate)\n",
    "            total_batches = i + 1\n",
    "\n",
    "        avg_cost = epoch_cost / total_batches\n",
    "        f.write(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)) +'\\n')\n",
    "        f.write(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,)+'\\n')\n",
    "        print(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)))\n",
    "        print(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_type(session,x):\n",
    "    inputs = {x_text_:x,#np array of texts\n",
    "             isTrain_: False} \n",
    "    pred = session.run([pred_max_],feed_dict=inputs)\n",
    "    return pred # batch x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.212\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on train set\n",
    "train_accuracy=[]\n",
    "preds = []\n",
    "\n",
    "# # pilot 1K\n",
    "# with open('results/MBTI16_LSTM_baseline_100HD_pilot1000.txt', 'a') as f:\n",
    "#     for i, (x,y) in enumerate(batch_generator(x_train[:1000], y_train_id[:1000], batch_size)):\n",
    "\n",
    "# # pilot 5k\n",
    "# with open('results/MBTI16_LSTM_baseline_100HD_pilot5000.txt', 'a') as f:\n",
    "#     for i, (x,y) in enumerate(batch_generator(x_train[:5000], y_train_id[:5000], batch_size)): \n",
    "\n",
    "# Full\n",
    "with open('results/MBTI16_LSTM_baseline_100HD.txt', 'a') as f:\n",
    "    for i, (x,y) in enumerate(batch_generator(x_train, y_train_id, batch_size)):\n",
    "        pred = predict_type(session,x)\n",
    "        train_accuracy.append((pred[0] == y).mean())\n",
    "        preds.append(pred[0])\n",
    "    f.write(\"Train accuracy: \" +str(float(np.mean(train_accuracy)))+'\\n')\n",
    "    print(\"Train accuracy: \" ,np.mean(train_accuracy))\n",
    "    # print samples\n",
    "    f.write(\"Train Samples: \\n\")\n",
    "    for i, sentence in enumerate(post_train[:10]):\n",
    "        f.write(\"(%s) %s \\n pred:%s \\n actual:%s \\n\" % (i,sentence,preds[0][i-1],y_train_id[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.203\n"
     ]
    }
   ],
   "source": [
    "# Accuray on test set\n",
    "test_accuracy = []\n",
    "preds = []\n",
    "\n",
    "# # Pilot 1K\n",
    "# with open('results/MBTI16_LSTM_baseline_100HD_pilot1000.txt', 'a') as f:\n",
    "#     for i, (x,y) in enumerate(batch_generator(x_test[:200], y_test_id[:200], batch_size)):\n",
    "\n",
    "# # Pilot 5K\n",
    "# with open('results/MBTI16_LSTM_baseline_100HD_pilot5000.txt', 'a') as f:\n",
    "#     for i, (x,y) in enumerate(batch_generator(x_test[:1000], y_test_id[:1000], batch_size)):\n",
    "\n",
    "# Full\n",
    "with open('results/MBTI16_LSTM_baseline_100HD.txt', 'a') as f:\n",
    "    for i, (x,y) in enumerate(batch_generator(x_test, y_test_id, batch_size)):\n",
    "        pred = predict_type(session,x)\n",
    "        test_accuracy.append((pred[0] == y).mean())\n",
    "        preds.append(pred[0])\n",
    "    f.write(\"Test accuracy: \" +str(float(np.mean(test_accuracy)))+'\\n')\n",
    "    print(\"Test accuracy: \" +str(float(np.mean(test_accuracy))))\n",
    "    f.write(\"Test Samples: \\n\")\n",
    "    for i, sentence in enumerate(post_test[:10]):\n",
    "        f.write(\"(%s) %s \\n pred:%s \\n actual:%s \\n\" % (i,sentence,preds[0][i],y_test_id[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_batch(session, x, y):\n",
    "    feed_dict = {x_text_:x,\n",
    "                 y_type_:y}\n",
    "    return session.run(loss_, feed_dict=feed_dict)\n",
    "\n",
    "def score_dataset(x, y):\n",
    "    total_cost = 0.0\n",
    "    total_batches = 0\n",
    "    for (x,y) in batch_generator(x, y, 5):\n",
    "        total_cost += score_batch(session, x, y)\n",
    "        total_batches += 1\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set perplexity: 9.653\n",
      "Test set perplexity: 9.736\n"
     ]
    }
   ],
   "source": [
    "# #for pilot 1K\n",
    "# train_perp = np.exp(score_dataset(x_train[:1000],y_train[:1000]))\n",
    "# test_perp = np.exp(score_dataset(x_test[:200],y_train[:200]))\n",
    "# print (\"Train set perplexity: %.03f\" % train_perp)\n",
    "# print (\"Test set perplexity: %.03f\" % test_perp)\n",
    "# with open('results/MBTI16_LSTM_baseline_100HD_pilot1000.txt', 'a') as f:\n",
    "#     f.write(\"Train set perplexity: %.03f \\n\" % train_perp)\n",
    "#     f.write(\"Test set perplexity: %.03f\" % test_perp)\n",
    "    \n",
    "    \n",
    "# # for pilot 5K\n",
    "# train_perp = np.exp(score_dataset(x_train[:5000],y_train[:5000]))\n",
    "# test_perp = np.exp(score_dataset(x_test[:1000],y_train[:1000]))\n",
    "# print (\"Train set perplexity: %.03f\" % train_perp)\n",
    "# print (\"Test set perplexity: %.03f\" % test_perp)\n",
    "# with open('results/MBTI16_LSTM_baseline_100HD_pilot5000.txt', 'a') as f:\n",
    "#     f.write(\"Train set perplexity: %.03f \\n\" % train_perp)\n",
    "#     f.write(\"Test set perplexity: %.03f\" % test_perp)\n",
    "    \n",
    "\n",
    "# Full\n",
    "train_perp = np.exp(score_dataset(x_train,y_train))\n",
    "test_perp = np.exp(score_dataset(x_test,y_test))\n",
    "print (\"Train set perplexity: %.03f\" % train_perp)\n",
    "print (\"Test set perplexity: %.03f\" % test_perp)\n",
    "with open('results/MBTI16_LSTM_baseline_100HD.txt', 'a') as f:\n",
    "    f.write(\"Train set perplexity: %.03f \\n\" % train_perp)\n",
    "    f.write(\"Test set perplexity: %.03f \\n\" % test_perp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[  0   0   1   0   0   0   0   0   0   0   0   1 178   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  37   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0 142   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  75   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  22   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 134   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  33   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0  20   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  10   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  16   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0  69   0   0   0]\n",
      " [  1   0   1   0   0   0   0   0   0   0   0   0 202   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   7   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEYCAYAAAApuP8NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIYwIiKi6fE/tpWF6kku4tAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "class_names = label_map.keys()\n",
    "\n",
    "# Compute confusion matrix\n",
    "test_predictions = np.array(preds).flatten()\n",
    "true = y_test_id\n",
    "cnf_matrix = confusion_matrix(true,test_predictions)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "fig1 = plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "fig1.savefig('results/mbti16-baseline-100HD-confusion.png')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "fig2 = plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "fig2.savefig('results/mbti16-baseline-100D-confusion-norm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
