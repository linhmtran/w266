{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBTI Binary E/I Classification w/ 1 Layer LST\n",
    "\n",
    "First, load libraries and useful functions from class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import json, os, re, shutil, sys, time\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# Utils and Helper libraries\n",
    "# import nltk\n",
    "from w266_common import utils, vocabulary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import MBTI_data_setup as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus & Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv('./mbti_1.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422845, 3)\n",
      "MBIT posts ['https://www.youtube.com/watch?v=bxvkaah2d7m'\n",
      " 'isfjs and infps can balance each other really well, i think, if they learn to communicate - sjs choosing words (and tone of voice!) carefully, and nps learning to take things less personally. your sj...'\n",
      " \"i'd seek recognition. not fame.\"\n",
      " \"to be honest, maybe you are giving out vibes that you are not self-assured. because if you think about it, a bully is going to go for someone they don't think will fight back, someone who is weak (i...\"\n",
      " \"probably. any thinking, really. personally, i prefer the ax-b-c-dy function stack compared to grant's. it allows for the parts where grant gets it right while still being consistent with jung, i.e.,...\"]\n",
      "\n",
      "MBTI Labels:  ['INTP' 'INFP' 'INTP' 'ENFP' 'INTJ']\n",
      "Vocab Size:  333007\n",
      "[8 7]\n",
      "[7 3]\n",
      "[[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "reload(ds)\n",
    "post, mbti_type, user = ds.splitPosts(df)\n",
    "\n",
    "# Split data: 80% train, 20% test\n",
    "post_train, post_test, label_train, label_test = train_test_split(post, mbti_type, test_size=0.2, random_state=88)\n",
    "\n",
    "print(\"MBIT posts\", post_train[:5])\n",
    "print('')\n",
    "print(\"MBTI Labels: \",label_train[:5])\n",
    "\n",
    "# Build a vocabulary (V size is defaulted to full text) for train corpus\n",
    "vocab_mbti = vocabulary.Vocabulary((utils.canonicalize_word(w) for w in post_train))\n",
    "print(\"Vocab Size: \",vocab_mbti.size)\n",
    "\n",
    "# tokenize and canonicalize train and test sets\n",
    "x_train = []\n",
    "for post in post_train:\n",
    "    x_train.append(vocab_mbti.words_to_ids(post.split()))\n",
    "\n",
    "x_test = []\n",
    "for post in post_test:\n",
    "    x_test.append(vocab_mbti.words_to_ids(post.split()))\n",
    "    \n",
    "reload(ds)\n",
    "y_train, y_test = ds.one_hot_label(mbti_type, label_train, label_test)\n",
    "y_train_id, y_test_id, label_map = ds.label_to_id(mbti_type, label_train, label_test)\n",
    "\n",
    "print(y_train_id[:2])\n",
    "print(y_test_id[:2])\n",
    "print(y_train[:2])\n",
    "print(y_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Y Train one hot for Training:  [[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "Example Y Train ID for Accuracy Scoring:  [1 1 1 0 1]\n",
      "Example Y Test one hot for Testing:  [[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "Example Y Train ID for Accuracy Scoring:  [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 4 dichotomomies: {Attitude: E/I, Information: N/S , Decision: F/T, Structure: J/P }\n",
    "mbti_map = {'E':0, 'I':1, 'N':2, 'S':3, 'F':4, 'T':5, 'J':6,'P':7 } # indicates the the index column for each type\n",
    "\n",
    "# split type string --> ['I' 'N' 'T' 'P']\n",
    "dichotomy_train = np.array([list(mbti_type) for mbti_type in label_train])\n",
    "dichotomy_test = np.array([list(mbti_type) for mbti_type in label_test])\n",
    "\n",
    "# convert dichotomy indicators to index value --> [1 2 5 7]\n",
    "y_train_id = np.array([list(map(lambda x: mbti_map[x],ind)) for ind in dichotomy_train])\n",
    "y_test_id = np.array([list(map(lambda x: mbti_map[x],ind)) for ind in dichotomy_test])\n",
    "\n",
    "# create 1-hot vector with MBTI dichotomies, map index value to 1 --> [0,1,1,0,1,0,1,0]\n",
    "one_hot_train = np.zeros((len(y_train_id),8),dtype=int)\n",
    "one_hot_test = np.zeros((len(y_test_id),8),dtype=int)\n",
    "for i in range(4):\n",
    "    one_hot_train[np.arange(len(dichotomy_train)), y_train_id[:,i]] = 1\n",
    "    one_hot_test[np.arange(len(dichotomy_test)), y_test_id[:,i]] = 1\n",
    "y_train = one_hot_train\n",
    "y_test = one_hot_test\n",
    "\n",
    "y_train = y_train[:,:2]\n",
    "print(\"Example Y Train one hot for Training: \", y_train[:5])\n",
    "y_train_id = y_train_id[:,0]\n",
    "print(\"Example Y Train ID for Accuracy Scoring: \", y_train_id[:5])\n",
    "\n",
    "\n",
    "y_test = y_test[:,:2]\n",
    "print(\"Example Y Test one hot for Testing: \", y_test[:5])\n",
    "y_test_id = y_test_id[:,0]\n",
    "print(\"Example Y Train ID for Accuracy Scoring: \", y_test_id[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulid the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "V = vocab_mbti.size\n",
    "classes = 2 #len(set(labels))\n",
    "batch_size = 25\n",
    "text_length = 70 # max sentence is 66\n",
    "embed_dim = 50 #256\n",
    "hidden_dims = 100 #\n",
    "num_layers = 1\n",
    "\n",
    "# Training Parameters\n",
    "dropout_keep_prob = .5\n",
    "softmax_ns = 4\n",
    "learning_rate = .001\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# useful functions for building LSTM\n",
    "def MakeFancyRNNCell(hidden_dims, keep_prob, layers=1, isTrain=True):\n",
    "    \"\"\"Make a fancy RNN cell.\n",
    "\n",
    "    Use tf.nn.rnn_cell functions to construct an LSTM cell.\n",
    "    Initialize forget_bias=0.0 for better training.\n",
    "\n",
    "    Args:\n",
    "      H: hidden state sizes, provided in array\n",
    "      keep_prob: dropout keep prob (same for input and output)\n",
    "\n",
    "    Returns:\n",
    "      (tf.nn.rnn_cell.RNNCell) multi-layer LSTM cell with dropout\n",
    "    \"\"\"\n",
    "    if isTrain == False:\n",
    "        keep_prob = 1.0\n",
    "\n",
    "    cells = []\n",
    "    for _ in range(layers):\n",
    "#         cell = tf.nn.rnn_cell.BasicLSTMCell(H, forget_bias=0.0) #deprecated?\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_dims, forget_bias=0.0,state_is_tuple=True)\n",
    "        cell = tf.nn.rnn_cell.DropoutWrapper(cell, \n",
    "                                             input_keep_prob=keep_prob, \n",
    "                                             output_keep_prob=keep_prob)\n",
    "        cells.append(cell)\n",
    "    return tf.nn.rnn_cell.MultiRNNCell(cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Input:  (?, ?, 50)\n",
      "LSTM Cell output shape:  (?, ?, 50)\n",
      "fully connected output shape:  (?, 50)\n",
      "W_out:  (50, 2)\n",
      "Logits:  (?, 2)\n",
      "Pred Prob Shape:  (?, 2)\n",
      "Pred Max Shape:  (?,)\n",
      "Sampling Shape:  (?, 1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(88)\n",
    "    \n",
    "# Create input placeholder\n",
    "with tf.name_scope(\"Inputs\"):\n",
    "    x_text_ = tf.placeholder(tf.int32, [None, None], name=\"x_text\") #batch x text_length\n",
    "    y_type_ = tf.placeholder(tf.int32, [None,classes], name=\"y_type\") #batch x classes\n",
    "\n",
    "    \n",
    "# Model params\n",
    "with tf.name_scope(\"Dynamic_Params\"):\n",
    "    # Get dynamic shape info from inputs\n",
    "    batch_size_ = tf.shape(x_text_)[0]\n",
    "    text_length_ = text_length\n",
    "    ns_ = tf.tile([text_length], [batch_size_, ], name=\"ns\")\n",
    "    isTrain_ = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "# Construct embedding layer\n",
    "with tf.name_scope(\"Embedding_Layer\"):\n",
    "#     W_in_ = tf.get_variable(tf.random_uniform(-1.0, 1.0),shape=[V, embed_dim], name=\"W_in\")\n",
    "    W_in_ = tf.Variable(tf.random_uniform([V, embed_dim], -1.0, 1.0), name=\"W_in\")\n",
    "    x_ = tf.nn.embedding_lookup(W_in_, x_text_,name='x')\n",
    "    print(\"Embedded Input: \", x_.shape)\n",
    "\n",
    "# Construct RNN/LSTM cell and recurrent layer.\n",
    "with tf.name_scope(\"Recurrent_Layer\"):\n",
    "    cell_lstm_ = MakeFancyRNNCell(hidden_dims, dropout_keep_prob, num_layers,isTrain_)\n",
    "    initial_h_ = cell_lstm_.zero_state(batch_size_, dtype=tf.float32)\n",
    "    output_, final_h_= tf.nn.dynamic_rnn(cell=cell_lstm_, inputs=x_, \n",
    "                                         sequence_length= ns_, initial_state = initial_h_, dtype=tf.float32)\n",
    "    print(\"LSTM Cell output shape: \",output_.shape)\n",
    "\n",
    "with tf.name_scope(\"Output_Layer\"):\n",
    "    h_ = tf.reduce_sum(output_, 1)\n",
    "    fully_connected_ = tf.layers.dense(h_, hidden_dims, activation=tf.tanh)\n",
    "    fc_do_ = tf.layers.dropout(inputs=fully_connected_, rate=(1-dropout_keep_prob), training=isTrain_)\n",
    "    if isTrain_==True:\n",
    "        fully_connected_ = fc_do_\n",
    "    print(\"fully connected output shape: \",fully_connected_.shape)\n",
    "    W_out_ = tf.Variable(tf.random_uniform([int(fully_connected_.shape[1]),classes],-1.0, 1.0), name=\"W_out\")\n",
    "    print(\"W_out: \",W_out_.shape)\n",
    "    b_out_ = tf.Variable(tf.zeros([classes,], dtype=tf.float32), name=\"b_out\")\n",
    "    logits_ = tf.add(tf.matmul(fully_connected_,W_out_), b_out_, name=\"logits\")\n",
    "    print(\"Logits: \",logits_.shape)\n",
    "    \n",
    "#     output_ = tf.reshape(output_, [batch_size_,text_length*hidden_dims])\n",
    "#     print(\"flattened output shape: \",output_.shape)\n",
    "#     W_out_ = tf.Variable(tf.random_uniform([hidden_dims*text_length,classes],-1.0, 1.0), name=\"W_out\")\n",
    "#     print(\"W_out: \",W_out_.shape)\n",
    "#     b_out_ = tf.Variable(tf.zeros([classes,], dtype=tf.float32), name=\"b_out\")\n",
    "#     logits_ = tf.add(tf.matmul(output_,W_out_), b_out_, name=\"logits\")\n",
    "#     print(\"Logits: \",logits_.shape)\n",
    "\n",
    "        \n",
    "\n",
    "with tf.name_scope(\"Cost_Function\"):\n",
    "    # Full softmax loss for training / scoring\n",
    "    per_example_loss_ = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_type_, \n",
    "                                                                   logits=logits_,\n",
    "                                                                   name=\"per_example_loss\")\n",
    "    loss_ = tf.reduce_mean(per_example_loss_, name=\"loss\")\n",
    "    \n",
    "    # Sampled softmax for training\n",
    "    train_inputs_ = tf.reshape(output_, [batch_size_*text_length_,-1])\n",
    "\n",
    "    per_example_sampled_softmax_loss_ = tf.nn.sampled_softmax_loss(weights=tf.transpose(W_out_),\n",
    "                                                                   biases=b_out_,\n",
    "                                                                   labels=tf.reshape(y_type_, [-1, 1]),\n",
    "                                                                   inputs=train_inputs_,\n",
    "                                                                   num_sampled=softmax_ns, \n",
    "                                                                   num_classes=classes,\n",
    "                                                                   name=\"per_example_sampled_softmax_loss\")\n",
    "\n",
    "    sampled_softmax_loss_ = tf.reduce_mean(per_example_sampled_softmax_loss_, name=\"sampled_softmax_loss\")\n",
    "    \n",
    "with tf.name_scope(\"Prediction\"):\n",
    "    pred_proba_ = tf.nn.softmax(logits_, name=\"pred_proba\")\n",
    "    pred_max_ = tf.argmax(logits_, 1, name=\"pred_max\")\n",
    "    pred_random_ = tf.reshape(tf.multinomial(tf.reshape(logits_ , [-1, classes]), \n",
    "                                                          1, \n",
    "                                                          output_dtype=tf.int32, \n",
    "                                                          name=\"pred_random\"),\n",
    "                                           [batch_size_,1])\n",
    "    print(\"Pred Prob Shape: \",pred_proba_.shape)\n",
    "    print(\"Pred Max Shape: \",pred_max_.shape)\n",
    "    print(\"Sampling Shape: \",pred_random_.shape)\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"Train\"):\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    optimizer_ = tf.train.AdamOptimizer(learning_rate_)\n",
    "    gradients, variables = zip(*optimizer_.compute_gradients(loss_))\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "    train_step_ = optimizer_.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "# Initializer step\n",
    "init_ = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w\n",
    "summary_writer = tf.summary.FileWriter(\"tf_graph\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create batched arrays of size batch_size based on input x and input y\n",
    "def pad_np_array(example_ids, max_len=text_length, pad_id=0):\n",
    "    arr = np.full([len(example_ids), max_len], pad_id, dtype=np.int32)\n",
    "    ns = np.zeros([len(example_ids)], dtype=np.int32)\n",
    "    for i, ids in enumerate(example_ids):\n",
    "        cpy_len = min(len(ids), max_len)\n",
    "        arr[i,:cpy_len] = ids[:cpy_len]\n",
    "        ns[i] = cpy_len\n",
    "    return arr, ns\n",
    "\n",
    "def batch_generator(x, y, batch_size):\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        # padd the batch\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        x_padded, _ = pad_np_array(x_batch, max_len=text_length, pad_id=0)\n",
    "        yield (x_padded, y[i:i+batch_size]) # returns tuple of batched x, batched y\n",
    "\n",
    "def train_batch(session, xbatch, ybatch, learning_rate):\n",
    "    feed_dict = {x_text_:xbatch, #np array of texts\n",
    "                 y_type_:ybatch, #np array of types\n",
    "                 learning_rate_:learning_rate}\n",
    "#     c, _ = session.run([sampled_softmax_loss_, train_step_],\n",
    "    c, _ = session.run([loss_, train_step_],\n",
    "                       feed_dict=feed_dict)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[epoch 1] seen 0 batches\n",
      "[epoch 1] Completed 199 batches in 0:00:33\n",
      "[epoch 1] Average cost: 0.582\n",
      "\n",
      "[epoch 2] seen 0 batches\n",
      "[epoch 2] Completed 199 batches in 0:00:30\n",
      "[epoch 2] Average cost: 0.552\n",
      "\n",
      "[epoch 3] seen 0 batches\n",
      "[epoch 3] Completed 199 batches in 0:00:30\n",
      "[epoch 3] Average cost: 0.552\n",
      "\n",
      "[epoch 4] seen 0 batches\n",
      "[epoch 4] Completed 199 batches in 0:00:30\n",
      "[epoch 4] Average cost: 0.552\n",
      "\n",
      "[epoch 5] seen 0 batches\n",
      "[epoch 5] Completed 199 batches in 0:00:29\n",
      "[epoch 5] Average cost: 0.552\n"
     ]
    }
   ],
   "source": [
    "print_interval = 1000\n",
    "\n",
    "np.random.seed(88)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(init_)\n",
    "\n",
    "t0 = time.time()\n",
    "# open('results/MBTI2_LSTM_L1_EI_100HD_pilot1000.txt', 'w').close()\n",
    "# with open('results/MBTI2_LSTM_L1_EI_100HD_pilot1000.txt', 'a') as f:\n",
    "#     f.write('TRAINING PILOT 1000 \\n')\n",
    "#     for epoch in range(1,num_epochs+1):\n",
    "#         t0_epoch = time.time()\n",
    "#         epoch_cost = 0.0\n",
    "#         total_batches = 0\n",
    "#         print (\"\")\n",
    "#         for i, (x,y) in enumerate(batch_generator(x_train[:1000], y_train[:1000], batch_size)): # for pilot\n",
    "#             if (i % print_interval == 0):\n",
    "#                 print(\"[epoch %d] seen %d batches\" % (epoch, i))\n",
    "\n",
    "#             epoch_cost += train_batch(session, x, y, learning_rate)\n",
    "#             total_batches = i + 1\n",
    "\n",
    "#         avg_cost = epoch_cost / total_batches\n",
    "#         f.write(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)) +'\\n')\n",
    "#         f.write(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,)+'\\n')\n",
    "#         print(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)))\n",
    "#         print(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,))\n",
    "        \n",
    "# # open('results/MBTI2_LSTM_L1_EI_100HD_pilot5000.txt', 'w').close()\n",
    "# with open('results/MBTI2_LSTM_L1_EI_100HD_pilot5000.txt', 'a') as f:\n",
    "#     f.write('TRAINING PILOT 5000 \\n')\n",
    "#     for epoch in range(1,num_epochs+1):\n",
    "#         t0_epoch = time.time()\n",
    "#         epoch_cost = 0.0\n",
    "#         total_batches = 0\n",
    "#         print (\"\")\n",
    "#         for i, (x,y) in enumerate(batch_generator(x_train[:5000], y_train[:5000], batch_size)): # for pilot\n",
    "#             if (i % print_interval == 0):\n",
    "#                 print(\"[epoch %d] seen %d batches\" % (epoch, i))\n",
    "\n",
    "#             epoch_cost += train_batch(session, x, y, learning_rate)\n",
    "#             total_batches = i + 1\n",
    "\n",
    "#         avg_cost = epoch_cost / total_batches\n",
    "#         f.write(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)) +'\\n')\n",
    "#         f.write(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,)+'\\n')\n",
    "#         print(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)))\n",
    "#         print(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,))\n",
    "\n",
    "open('results/MBTI2_LSTM_L1_EI_100HD.txt', 'w').close()\n",
    "with open('results/MBTI2_LSTM_L1_EI_100HD.txt', 'a') as f:\n",
    "    f.write('TRAINING Full \\n')\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        epoch_cost = 0.0\n",
    "        total_batches = 0\n",
    "        print (\"\")\n",
    "        for i, (x,y) in enumerate(batch_generator(x_train, y_train, batch_size)):\n",
    "            if (i % print_interval == 0):\n",
    "                print(\"[epoch %d] seen %d batches\" % (epoch, i))\n",
    "\n",
    "            epoch_cost += train_batch(session, x, y, learning_rate)\n",
    "            total_batches = i + 1\n",
    "\n",
    "        avg_cost = epoch_cost / total_batches\n",
    "        f.write(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)) +'\\n')\n",
    "        f.write(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,)+'\\n')\n",
    "        print(\"[epoch %d] Completed %d batches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch)))\n",
    "        print(\"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_type(session,x):\n",
    "    inputs = {x_text_:x,#np array of texts\n",
    "             isTrain_: False} \n",
    "    pred = session.run([pred_max_],feed_dict=inputs)\n",
    "    return pred # batch x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7718\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on train set\n",
    "train_accuracy=[]\n",
    "preds = []\n",
    "\n",
    "# # pilot 1K\n",
    "# with open('results/MBTI2_LSTM_L1_EI_100HD_pilot1000.txt', 'a') as f:\n",
    "#     for i, (x,y) in enumerate(batch_generator(x_train[:1000], y_train_id[:1000], batch_size)):\n",
    "\n",
    "# # pilot 5k\n",
    "# with open('results/MBTI2_LSTM_L1_EI_100HD_pilot5000.txt', 'a') as f:\n",
    "#     for i, (x,y) in enumerate(batch_generator(x_train[:5000], y_train_id[:5000], batch_size)): \n",
    "\n",
    "# Full\n",
    "with open('results/MBTI2_LSTM_L1_EI_100HD.txt', 'a') as f:\n",
    "    for i, (x,y) in enumerate(batch_generator(x_train, y_train_id, batch_size)):\n",
    "        \n",
    "        pred = predict_type(session,x)\n",
    "        train_accuracy.append((pred[0] == y).mean())\n",
    "        preds.append(pred[0])\n",
    "    f.write(\"Train accuracy: \" +str(float(np.mean(train_accuracy)))+'\\n')\n",
    "    print(\"Train accuracy: \" ,np.mean(train_accuracy))\n",
    "    # print samples\n",
    "    f.write(\"Train Samples: \\n\")\n",
    "    for i, sentence in enumerate(post_train[:10]):\n",
    "        f.write(\"(%s) %s \\n pred:%s \\n actual:%s \\n\" % (i,sentence,preds[0][i-1],y_train_id[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.772\n"
     ]
    }
   ],
   "source": [
    "# Accuray on test set\n",
    "test_accuracy = []\n",
    "preds = []\n",
    "\n",
    "# # Pilot 1K\n",
    "# with open('results/MBTI2_LSTM_L1_EI_100HD_pilot1000.txt', 'a') as f:\n",
    "#     for i, (x,y) in enumerate(batch_generator(x_test[:200], y_test_id[:200], batch_size)):\n",
    "\n",
    "# # Pilot 5K\n",
    "# with open('results/MBTI2_LSTM_L1_EI_100HD_pilot5000.txt', 'a') as f:\n",
    "#     for i, (x,y) in enumerate(batch_generator(x_test[:1000], y_test_id[:1000], batch_size)):\n",
    "\n",
    "# Full\n",
    "with open('results/MBTI2_LSTM_L1_EI_100HD.txt', 'a') as f:\n",
    "    for i, (x,y) in enumerate(batch_generator(x_test, y_test_id, batch_size)):\n",
    "        \n",
    "        pred = predict_type(session,x)\n",
    "        test_accuracy.append((pred[0] == y).mean())\n",
    "        preds.append(pred[0])\n",
    "    f.write(\"Test accuracy: \" +str(float(np.mean(test_accuracy)))+'\\n')\n",
    "    print(\"Test accuracy: \" +str(float(np.mean(test_accuracy))))\n",
    "    f.write(\"Test Samples: \\n\")\n",
    "    for i, sentence in enumerate(post_test[:10]):\n",
    "        f.write(\"(%s) %s \\n pred:%s \\n actual:%s \\n\" % (i,sentence,preds[0][i],y_test_id[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_batch(session, x, y):\n",
    "    feed_dict = {x_text_:x,\n",
    "                 y_type_:y}\n",
    "    return session.run(loss_, feed_dict=feed_dict)\n",
    "\n",
    "def score_dataset(x, y):\n",
    "    total_cost = 0.0\n",
    "    total_batches = 0\n",
    "    for (x,y) in batch_generator(x, y, 5):\n",
    "        total_cost += score_batch(session, x, y)\n",
    "        total_batches += 1\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set perplexity: 1.723\n",
      "Test set perplexity: 1.717\n"
     ]
    }
   ],
   "source": [
    "# #for pilot 1K\n",
    "# train_perp = np.exp(score_dataset(x_train[:1000],y_train[:1000]))\n",
    "# test_perp = np.exp(score_dataset(x_test[:200],y_train[:200]))\n",
    "# print (\"Train set perplexity: %.03f\" % train_perp)\n",
    "# print (\"Test set perplexity: %.03f\" % test_perp)\n",
    "# with open('results/MBTI2_LSTM_L1_EI_100HD_pilot1000.txt', 'a') as f:\n",
    "#     f.write(\"Train set perplexity: %.03f \\n\" % train_perp)\n",
    "#     f.write(\"Test set perplexity: %.03f\" % test_perp)\n",
    "    \n",
    "    \n",
    "# # for pilot 5K\n",
    "# train_perp = np.exp(score_dataset(x_train[:5000],y_train[:5000]))\n",
    "# test_perp = np.exp(score_dataset(x_test[:1000],y_train[:1000]))\n",
    "# print (\"Train set perplexity: %.03f\" % train_perp)\n",
    "# print (\"Test set perplexity: %.03f\" % test_perp)\n",
    "# with open('results/MBTI2_LSTM_L1_EI_100HD_pilot5000.txt', 'a') as f:\n",
    "#     f.write(\"Train set perplexity: %.03f \\n\" % train_perp)\n",
    "#     f.write(\"Test set perplexity: %.03f\" % test_perp)\n",
    "    \n",
    "\n",
    "# Full\n",
    "train_perp = np.exp(score_dataset(x_train,y_train))\n",
    "test_perp = np.exp(score_dataset(x_test,y_test))\n",
    "print (\"Train set perplexity: %.03f\" % train_perp)\n",
    "print (\"Test set perplexity: %.03f\" % test_perp)\n",
    "with open('results/MBTI2_LSTM_L1_EI_100HD.txt', 'a') as f:\n",
    "    f.write(\"Train set perplexity: %.03f \\n\" % train_perp)\n",
    "    f.write(\"Test set perplexity: %.03f \\n\" % test_perp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "test_predictions = np.array(preds).flatten()\n",
    "true = y_test_id\n",
    "\n",
    "average_precision = average_precision_score(true, test_predictions)\n",
    "with open('results/MBTI2_LSTM_L1_EI_100HD.txt', 'a') as f:\n",
    "    f.write('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "    print('Average precision-recall score: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
